---
title: "Assignment 2"
author: "Group 2"
#?format: pdf
output: html
editor: visual
date: Feb-18-2024
execute: 
  warning: false
  message: false
---

```{r, echo=FALSE}
library(tidyverse)
library(here)
library(sf)
library(tigris)
```

### Question 1

Our group discussed that we need to expand the LAT data set with multiple locations. This is because, once we done that,the unite of analysis in the cleaned data set would be per labor action and per location. Each row will only contain one geographical location. In this case, we can build correlations to find which country may have higher possibilities to have a certain type of labor action. Moreover, in this case, we can combine geo-econ data into each row, such as GDP, working population etc. according to each location. If we did not separate the locations, some rows may have multiple locations and also more than one geo-econ data.

```{r}
LAT <- readxl::read_xlsx(here("Data Raw/Labor action tracker data 12.4.23.xlsx"))

data <- LAT %>%
  mutate(
    coordinate = ifelse(
      `Number of Locations` > 1,
      strsplit(as.character(`Latitude, Longitude`), ";\\s*"),
      `Latitude, Longitude`
    ))%>%  
  unnest(coordinate)
```

### Question 2

```{r, eval=FALSE}
library(cdlTools)
library(sp)
library(maps)
```

These are coding solutions generated by Chatgpt.

1\. Stack overflow suggestion

```{r, eval=FALSE}
latlong2county <- function(pointsDF) {
    # Prepare SpatialPolygons object with one SpatialPolygon
    # per county
    counties <- map('county', fill=TRUE, col="transparent", plot=FALSE)
    IDs <- sapply(strsplit(counties$names, ":"), function(x) x[1])
    counties_sp <- map2SpatialPolygons(counties, IDs=IDs,
                     proj4string=CRS("+proj=longlat +datum=WGS84"))
    # Convert pointsDF to a SpatialPoints object 
    pointsSP <- SpatialPoints(pointsDF, 
                    proj4string=CRS("+proj=longlat +datum=WGS84"))
    # Use 'over' to get _indices_ of the Polygons object containing each point 
    indices <- over(pointsSP, counties_sp)
    # Return the county names of the Polygons object containing each point
    countyNames <- sapply(counties_sp@polygons, function(x) x@ID)
    countyNames[indices]
}

data_latlong <- separate(data_clean, `Latitude, Longitude`, into = c("x", "y"), sep = ",", convert = TRUE)
data_latlong <- data.frame(x=data_latlong$x, y=data_latlong$y)
coordinates(data_latlong) <- c("x", "y")
proj4string(data_latlong) <- CRS("+proj=longlat +datum=WGS84")
latlong2county(data_latlong)
```

2\. Suggestion with package *rnaturalearth.*

```{r, eval=FALSE}
# Load required packages
library(rnaturalearth)
library(sf)

# Load the US counties data
us_counties <- ne_states(country = "united states", returnclass = "sf")
# Sample DataFrame with latitude and longitude columns
df <- data.frame(Latitude = c(40.7128, 34.0522, 51.5074),
                 Longitude = c(-74.0060, -118.2437, -0.1278))
# Convert DataFrame to SpatialPointsDataFrame
coordinates(df) <- c("Longitude", "Latitude")
proj4string(df) <- CRS("+proj=longlat +datum=WGS84")
# Convert SpatialPointsDataFrame to sf object
df_sf <- st_as_sf(df)
# Set the projection to match with US counties data
st_crs(df_sf) <- st_crs(us_counties)
# Perform spatial join to find US counties for each point
result <- st_join(df_sf, us_counties)
print(result)
```

3\. Suggestion with *tigris* package. (Final version. Our group will be using this solution to generate county variable.)

```{r, output=FALSE}
# retrieve data frame from tigris package that contains US counties infomation and geometric data
county <- tigris::counties(cb = TRUE)
# the goal is to join 2 data frame with geometric attributes.
# but first, convert LAT data into geometric data frame with coordinates
# the transformation require separate longtitude and latitude information
data <- separate(data, coordinate, into = c("lat", "lon"), 
                 sep = ",\\s*", remove = FALSE)
# check is there any NAs 
data <- data %>%
  mutate(
    lat = as.numeric(lat),
    lon = as.numeric(lon))
na_summary <- data %>%
  summarise_all(~ sum(is.na(.)))
# yes, there is one in lon column. 
data$lon[2830] = -85.73642799999999
# transform LAT data into geometric data frame
data <- st_as_sf(data, coords = c("lon", "lat"))
# matching same projection
st_crs(data) <- st_crs(county)
# joining 2 geometric data frames
data <- st_join(data, county)
# housekeeping and make LAT data looks clean and organized
vars <- names(LAT)
data <- data %>%
  select(c(vars, NAME, GEOID)) %>%
  rename(county = NAME) %>%
  select(1:10, 23, 11:22, 24:25)
```

In general, Chatgpt is helpful in terms of offering basic ideas of how we can acheive it. It shows that in order to generate a variable that contains US county names with Lon/Lat data, the basic idea is to match and join the LAT data with a data frame that has US county information. Without specific instruction, however, Chatgpt would generate complicated solution with redundant codes and rarely used packages. Because our group has team members who took QGIS prior to the course and are familiar with *sf* package. In this case, with the basic ideas and reference of packages that can retrieve US county information from Chatgpt, It would be more convenient and helpful than just simply relying on Chatgpt to generate the solution from scratch.

### Question 3

```{r, fig.width=3, fig.height=3}
gt::gt(head(data))
knitr::kable(head(data))
```
